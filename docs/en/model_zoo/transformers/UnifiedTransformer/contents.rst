------------------------------------
UnifiedTransformer Model Summary
------------------------------------

The following table summarizes the currently supported UnifiedTransformer models and their corresponding pretrained weights in PaddleNLP. For specific model details, please refer to the corresponding links.

+----------------------------------------------------------------------------------+--------------+----------------------------------------------------------------------------------+
| Pretrained Weight                                                                | Language     | Details of the model                                                             |
+==================================================================================+==============+==================================================================================+
|``unified_transformer-12L-cn``                                                    | Chinese      | 12-layer, 768-hidden,                                                            |
|                                                                                  |              | 12-heads, 108M parameters.                                                       |
|                                                                                  |              | Trained on Chinese text.                                                         |
+----------------------------------------------------------------------------------+--------------+----------------------------------------------------------------------------------+
|``unified_transformer-12L-cn-luge``
|``plato-xl``                                                                      | Chinese      | 24-layer, 1024-hidden,                                                           |
|                                                                                  |              | 16-heads, 400M parameters.                                                       |
|                                                                                  |              | Trained on Chinese text.                                                         |
+----------------------------------------------------------------------------------+--------------+----------------------------------------------------------------------------------+
+----------------------------------------------------------------------------------+--------------+----------------------------------------------------------------------------------+
| 72-layer, 3072-hidden,                                                          | 32-heads, ?M parameters.                                                        |
| Trained on Chinese text.                                                         |
+----------------------------------------------------------------------------------+--------------+----------------------------------------------------------------------------------+