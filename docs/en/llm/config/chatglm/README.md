# ChatGLM-6B

## 1. Model Overview

ChatGLM-6B is an open-source dialogue language model that supports Chinese-English bilingual QA, based on the [General Language Model (GLM)](https://arxiv.org/abs/2103.10360) architecture with 6.2 billion parameters. Using the same techniques as ChatGLM, ChatGLM-6B is optimized for Chinese QA and dialogue. Trained on approximately 1T tokens of Chinese-English bilingual corpus, and enhanced with supervised fine-tuning, feedback bootstrap, and RLHF, this 6.2B parameter model can generate responses well-aligned with human preferences.

**Supported Model Weights:**

| Model                 |
|-----------------------|
| THUDM/chatglm-6b      |
| THUDM/chatglm-6b-v1.1 |

## 2. Model License

The use of ChatGLM-6B model weights must comply with the [License](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/paddlenlp/transformers/chatglm/LICENSE).
